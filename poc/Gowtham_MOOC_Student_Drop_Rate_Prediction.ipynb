{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOOC_Student_Drop_Rate_Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 1 : PREDICTIONS using rfc_mim.pkl -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n",
    "# Removing duplicate rows\n",
    "duplicate_index = data[data.drop(['enrollment_id', 'startdate', 'enddate'], axis=1).duplicated()].index\n",
    "data = data.drop(duplicate_index)\n",
    "# Removing Outliers\n",
    "data = data[data['access']<700]\n",
    "data = data[data['discussion']<1000]\n",
    "data = data[data['navigate']<200]\n",
    "data = data[data['page_close']<250]\n",
    "data = data[data['problem']<750]\n",
    "data = data[data['video']<250]\n",
    "data = data[data['wiki']<120]\n",
    "data = data[data['effective_time']<255]\n",
    "# Droping independent features\n",
    "data.drop(['page_close', 'video', 'proccess_period'], axis=1, inplace=True)\n",
    "# Extracting extra feature from Start_Date and End_Date\n",
    "duration_in_days = (data['enddate'] - data['startdate']).dt.days + 1\n",
    "data.insert(8,\"duration_in_days\", duration_in_days)\n",
    "# Splitting the data using train_test_split\n",
    "train, test = train_test_split(data.iloc[:, 3:], test_size=0.3, random_state=0)\n",
    "X_test = test.drop(['dropout_prob'], axis=1)\n",
    "y_test = test['dropout_prob']\n",
    "# Upsampling data i.e., Minor to Major\n",
    "dropout_minor = train[train.dropout_prob==0]\n",
    "dropout_major = train[train.dropout_prob==1]\n",
    "dropout_upsampled = resample(dropout_minor,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(dropout_major), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([dropout_major, dropout_upsampled])\n",
    "y_train = upsampled.dropout_prob\n",
    "X_train = upsampled.drop(['dropout_prob'], axis=1)\n",
    "X_train = X_train[['duration_in_days', 'access', 'discussion', 'navigate', 'problem', 'wiki', 'present_days', 'effective_time', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'holidays', 'course_enroll', 'user_enroll', 'course_drop_rate']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting result with RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion = 'entropy', random_state = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Training Score : \", classifier.score(X_train, y_train))\n",
    "print(\"Testing Score : \", classifier.score(X_test, y_test))\n",
    "\n",
    "# Generating Pickle file\n",
    "pickle.dump(classifier, open('pkl_rfc_mim.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2 : PREDICTIONS using rf_model_feature_10.pkl ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is created by Mr. Amar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 3 : PREDICTIONS using pkl_rfc_log_norm_scale_ggm.pkl ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n",
    "# Removing duplicate rows\n",
    "duplicate_index = data[data.drop('enrollment_id', axis=1).duplicated()].index\n",
    "data = data.drop(duplicate_index)\n",
    "# Removing Outliers\n",
    "data = data[data['access']<700]\n",
    "data = data[data['discussion']<1000]\n",
    "data = data[data['navigate']<200]\n",
    "data = data[data['page_close']<250]\n",
    "data = data[data['problem']<750]\n",
    "data = data[data['video']<250]\n",
    "data = data[data['wiki']<120]\n",
    "data = data[data['effective_time']<255]\n",
    "\n",
    "# Extracting extra feature from Start_Date and End_Date\n",
    "duration_in_days = (data['enddate'] - data['startdate']).dt.days + 1\n",
    "data.insert(11,\"duration_in_days\", duration_in_days)\n",
    "\n",
    "# Exclude independent features ('page_close', 'video', 'proccess_period') which are highly correlated \n",
    "# Include independent features ('effective_time', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'holidays', 'course_enroll', 'user_enroll', 'course_drop_rate') \n",
    "data = data[['duration_in_days', 'present_days', 'access', 'discussion', 'navigate', 'problem', 'wiki', 'dropout_prob']]\n",
    "\n",
    "# Spliting Input and Output features and scaling X data and concatenate into \"data\"\n",
    "y = data['dropout_prob']\n",
    "X = data.drop('dropout_prob', axis=1)\n",
    "# Log\n",
    "X_log = np.log(X+1)\n",
    "# Normalizing\n",
    "X_norm = preprocessing.normalize(X_log)\n",
    "X_norm = pd.DataFrame(X_norm, index= X.index, columns=X.columns)\n",
    "# Scaling the Input features\n",
    "ss_scale = StandardScaler()\n",
    "X_scale = scale.fit_transform(X_norm)\n",
    "X_scale = pd.DataFrame(X_scale, index=X.index, columns=X.columns)\n",
    "# Concatenating\n",
    "data = pd.concat([X_scale, y], axis=1)\n",
    "# Splitting training and testing data using train_test_split()\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=0)\n",
    "X_test = test.drop(['dropout_prob'], axis=1)\n",
    "y_test = test['dropout_prob']\n",
    "# Upsampling data i.e., Minor to Major\n",
    "dropout_minor = train[train.dropout_prob==0]\n",
    "dropout_major = train[train.dropout_prob==1]\n",
    "dropout_upsampled = resample(dropout_minor,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(dropout_major), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([dropout_major, dropout_upsampled])\n",
    "y_train = upsampled.dropout_prob\n",
    "X_train = upsampled.drop(['dropout_prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score :  0.9362165008452734\n",
      "Testing Score :  0.8066576155277316\n"
     ]
    }
   ],
   "source": [
    "# Predicting result with RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion = 'entropy', random_state = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Generating Pickle file\n",
    "pickle.dump(classifier, open('pkl_rfc_log_norm_scale_ggm.pkl', 'wb'))\n",
    "print(\"Training Score : \", classifier.score(X_train, y_train))\n",
    "print(\"Testing Score : \", classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 4 : PREDICTIONS using pkl_rfc_log_norm_scale_ggm.pkl with input as Excel file ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n",
    "# Removing duplicate rows\n",
    "duplicate_index = data[data.drop('enrollment_id', axis=1).duplicated()].index\n",
    "data = data.drop(duplicate_index)\n",
    "# Removing Outliers\n",
    "data = data[data['access']<700]\n",
    "data = data[data['discussion']<1000]\n",
    "data = data[data['navigate']<200]\n",
    "data = data[data['page_close']<250]\n",
    "data = data[data['problem']<750]\n",
    "data = data[data['video']<250]\n",
    "data = data[data['wiki']<120]\n",
    "data = data[data['effective_time']<255]\n",
    "\n",
    "X = data[['enrollment_id', 'startdate', 'enddate', 'access', 'discussion', 'navigate',  \"page_close\", 'problem', \"video\", 'wiki']]\n",
    "X.columns = ['enrollment_id', 'start_date', 'end_date', 'access', 'discussion', 'navigate',  \"page_close\", 'problem', \"video\", 'wiki']\n",
    "y = data['dropout_prob']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_test.to_csv(\"X_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing input data with the pickle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollment_id                  57763\n",
       "start_date       2013-11-12 00:00:00\n",
       "end_date         2013-12-09 00:00:00\n",
       "access                           118\n",
       "discussion                         7\n",
       "navigate                          27\n",
       "page_close                        79\n",
       "problem                           37\n",
       "video                             36\n",
       "wiki                               2\n",
       "Name: 57762, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[57762]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = 2004\n",
    "def Leap_Year(Year):\n",
    "    C1 = Year%400==0 \n",
    "    C2 = Year%4==0\n",
    "    C3 = Year%100!=0\n",
    "\n",
    "    if C1 | (C2 & C3):\n",
    "        return \"Leap Year\"\n",
    "    else:\n",
    "        return \"Not Leap Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "Num = 735382\n",
    "\n",
    "count=0\n",
    "for i in range(1, math.floor(Num/365)):\n",
    "    if Leap_Year(i)==\"Leap Year\":\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 149)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor((Num-count)/365), (Num-count)%365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 4, 24)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor((Num-count)/365), math.floor((149-5)/30), (149-5)%30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data frame from input excel file\n",
    "# df = pd.read_csv(\"sdo_test_csv_file\")\n",
    "df = X_test.copy()\n",
    "\n",
    "# Converting data-time format\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "# Extracting new feature from start_date and end_date\n",
    "present_days = (df[\"end_date\"] - df[\"start_date\"]).dt.days + 1\n",
    "df.insert(3, \"present_days\", present_days)\n",
    "df['start_date'] = df['start_date'].map(datetime.toordinal)\n",
    "df['end_date'] = df['end_date'].map(datetime.toordinal)\n",
    "X = df.drop('enrollment_id', axis=1)\n",
    "# Scalling the data\n",
    "scale = StandardScaler()\n",
    "X_scale = scale.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale, index=X.index, columns=X.columns)\n",
    "# Initialising Pickle file\n",
    "model = pickle.load(open(\"pkl_rf_model_feature_10.pkl\", \"rb\"))\n",
    "# Model Prediction\n",
    "pred_val = model.predict(X_scale)\n",
    "df['result'] = pred_val\n",
    "df.to_csv('X_test_Pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### =============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def processing(self, df):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def processing(self, df):\n",
    "        # Converting Dates into ordinals\n",
    "        df = self.dates_to_ordinals(df)\n",
    "        # Extracting new \"present_days\" feature from \"start_date\" and \"end_date\" features\n",
    "        df = self.extract_features(df)\n",
    "        # Scaling the values\n",
    "        df = self.stadardise_values(df)\n",
    "        return df\n",
    "    \n",
    "    # Converting Dates into ordinals\n",
    "    def dates_to_ordinals(self, df):\n",
    "        df['start_date'] = pd.to_datetime(df['start_date']).apply(lambda x : x.toordinal())\n",
    "        df['end_date'] = pd.to_datetime(df['end_date']).apply(lambda x : x.toordinal())\n",
    "        return df\n",
    "\n",
    "    # Extracting new \"present_days\" feature from \"start_date\" and \"end_date\" features\n",
    "    def extract_features(self, df):\n",
    "        present_days = df['end_date'] - df['start_date'] + 1\n",
    "        df.insert(2, 'present_days', present_days)\n",
    "        return df\n",
    "\n",
    "    # Scaling the values\n",
    "    def stadardise_values(self, df):\n",
    "        scale = StandardScaler()\n",
    "        arr = scale.fit_transform(df)\n",
    "        df = pd.DataFrame(arr, columns=df.columns)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('X_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>page_close</th>\n",
       "      <th>problem</th>\n",
       "      <th>video</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-29</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>185</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>124</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date  access  discussion  navigate  page_close  problem  \\\n",
       "2  2014-05-29  2014-06-24     185          70        36         124       36   \n",
       "\n",
       "   video  wiki  \n",
       "2     50     1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =data.iloc[2:3, 1:]\n",
    "X = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>present_days</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>page_close</th>\n",
       "      <th>problem</th>\n",
       "      <th>video</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  end_date  present_days  access  discussion  navigate  \\\n",
       "0         0.0       0.0           0.0     0.0         0.0       0.0   \n",
       "\n",
       "   page_close  problem  video  wiki  \n",
       "0         0.0      0.0    0.0   0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = preprocessing()\n",
    "df = p.processing(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Initialising Pickle file\n",
    "model = pickle.load(open(\"pkl_rf_model_feature_10.pkl\", \"rb\"))\n",
    "# Model Prediction\n",
    "X['result'] = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>present_days</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>page_close</th>\n",
       "      <th>problem</th>\n",
       "      <th>video</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428159</td>\n",
       "      <td>0.588445</td>\n",
       "      <td>1.245585</td>\n",
       "      <td>1.094722</td>\n",
       "      <td>2.295614</td>\n",
       "      <td>1.303439</td>\n",
       "      <td>2.281465</td>\n",
       "      <td>0.777817</td>\n",
       "      <td>2.161336</td>\n",
       "      <td>0.538816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.985379</td>\n",
       "      <td>-1.925540</td>\n",
       "      <td>0.653624</td>\n",
       "      <td>0.381211</td>\n",
       "      <td>0.294595</td>\n",
       "      <td>0.452214</td>\n",
       "      <td>0.788377</td>\n",
       "      <td>1.107801</td>\n",
       "      <td>0.912199</td>\n",
       "      <td>0.538816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.412468</td>\n",
       "      <td>-1.518866</td>\n",
       "      <td>-0.727619</td>\n",
       "      <td>-0.666040</td>\n",
       "      <td>0.383529</td>\n",
       "      <td>-0.399012</td>\n",
       "      <td>-0.447283</td>\n",
       "      <td>1.814907</td>\n",
       "      <td>-0.205450</td>\n",
       "      <td>0.538816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720709</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>-1.319581</td>\n",
       "      <td>-1.011287</td>\n",
       "      <td>-0.817083</td>\n",
       "      <td>-1.108367</td>\n",
       "      <td>-0.884913</td>\n",
       "      <td>-0.919239</td>\n",
       "      <td>-1.060123</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.793847</td>\n",
       "      <td>0.637739</td>\n",
       "      <td>-1.319581</td>\n",
       "      <td>-0.999779</td>\n",
       "      <td>-0.817083</td>\n",
       "      <td>-1.179302</td>\n",
       "      <td>-0.884913</td>\n",
       "      <td>-0.919239</td>\n",
       "      <td>-1.060123</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.440349</td>\n",
       "      <td>0.576121</td>\n",
       "      <td>1.048265</td>\n",
       "      <td>1.923315</td>\n",
       "      <td>0.161193</td>\n",
       "      <td>1.729052</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>-0.494975</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>1.975658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.403780</td>\n",
       "      <td>0.514504</td>\n",
       "      <td>0.850944</td>\n",
       "      <td>-0.021578</td>\n",
       "      <td>-0.817083</td>\n",
       "      <td>-0.328077</td>\n",
       "      <td>-0.498769</td>\n",
       "      <td>-0.730677</td>\n",
       "      <td>-0.271194</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.611003</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>-0.431638</td>\n",
       "      <td>-0.700564</td>\n",
       "      <td>-0.683682</td>\n",
       "      <td>-0.469948</td>\n",
       "      <td>-0.395797</td>\n",
       "      <td>-0.636396</td>\n",
       "      <td>-0.336938</td>\n",
       "      <td>-0.898027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  end_date  present_days    access  discussion  navigate  \\\n",
       "0    0.428159  0.588445      1.245585  1.094722    2.295614  1.303439   \n",
       "1   -1.985379 -1.925540      0.653624  0.381211    0.294595  0.452214   \n",
       "2   -1.412468 -1.518866     -0.727619 -0.666040    0.383529 -0.399012   \n",
       "3    0.720709  0.563798     -1.319581 -1.011287   -0.817083 -1.108367   \n",
       "4    0.793847  0.637739     -1.319581 -0.999779   -0.817083 -1.179302   \n",
       "5    0.440349  0.576121      1.048265  1.923315    0.161193  1.729052   \n",
       "6    0.403780  0.514504      0.850944 -0.021578   -0.817083 -0.328077   \n",
       "7    0.611003  0.563798     -0.431638 -0.700564   -0.683682 -0.469948   \n",
       "\n",
       "   page_close   problem     video      wiki  \n",
       "0    2.281465  0.777817  2.161336  0.538816  \n",
       "1    0.788377  1.107801  0.912199  0.538816  \n",
       "2   -0.447283  1.814907 -0.205450  0.538816  \n",
       "3   -0.884913 -0.919239 -1.060123 -0.898027  \n",
       "4   -0.884913 -0.919239 -1.060123 -0.898027  \n",
       "5    0.041832 -0.494975 -0.139706  1.975658  \n",
       "6   -0.498769 -0.730677 -0.271194 -0.898027  \n",
       "7   -0.395797 -0.636396 -0.336938 -0.898027  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>page_close</th>\n",
       "      <th>problem</th>\n",
       "      <th>video</th>\n",
       "      <th>wiki</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-29</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>185</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>124</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date  access  discussion  navigate  page_close  problem  \\\n",
       "2  2014-05-29  2014-06-24     185          70        36         124       36   \n",
       "\n",
       "   video  wiki  result  \n",
       "2     50     1       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_date': '2014-05-29',\n",
       "  'end_date': '2014-06-24',\n",
       "  'access': 185,\n",
       "  'discussion': 70,\n",
       "  'navigate': 36,\n",
       "  'page_close': 124,\n",
       "  'problem': 36,\n",
       "  'video': 50,\n",
       "  'wiki': 1,\n",
       "  'result': 0},\n",
       " {'start_date': '2013-11-12',\n",
       "  'end_date': '2013-12-02',\n",
       "  'access': 123,\n",
       "  'discussion': 25,\n",
       "  'navigate': 24,\n",
       "  'page_close': 66,\n",
       "  'problem': 43,\n",
       "  'video': 31,\n",
       "  'wiki': 1,\n",
       "  'result': 1},\n",
       " {'start_date': '2013-12-29',\n",
       "  'end_date': '2014-01-04',\n",
       "  'access': 32,\n",
       "  'discussion': 27,\n",
       "  'navigate': 12,\n",
       "  'page_close': 18,\n",
       "  'problem': 58,\n",
       "  'video': 14,\n",
       "  'wiki': 1,\n",
       "  'result': 1},\n",
       " {'start_date': '2014-06-22',\n",
       "  'end_date': '2014-06-22',\n",
       "  'access': 2,\n",
       "  'discussion': 0,\n",
       "  'navigate': 2,\n",
       "  'page_close': 1,\n",
       "  'problem': 0,\n",
       "  'video': 1,\n",
       "  'wiki': 0,\n",
       "  'result': 1},\n",
       " {'start_date': '2014-06-28',\n",
       "  'end_date': '2014-06-28',\n",
       "  'access': 3,\n",
       "  'discussion': 0,\n",
       "  'navigate': 1,\n",
       "  'page_close': 1,\n",
       "  'problem': 0,\n",
       "  'video': 1,\n",
       "  'wiki': 0,\n",
       "  'result': 1},\n",
       " {'start_date': '2014-05-30',\n",
       "  'end_date': '2014-06-23',\n",
       "  'access': 257,\n",
       "  'discussion': 22,\n",
       "  'navigate': 42,\n",
       "  'page_close': 37,\n",
       "  'problem': 9,\n",
       "  'video': 15,\n",
       "  'wiki': 2,\n",
       "  'result': 0},\n",
       " {'start_date': '2014-05-27',\n",
       "  'end_date': '2014-06-18',\n",
       "  'access': 88,\n",
       "  'discussion': 0,\n",
       "  'navigate': 13,\n",
       "  'page_close': 16,\n",
       "  'problem': 4,\n",
       "  'video': 13,\n",
       "  'wiki': 0,\n",
       "  'result': 1},\n",
       " {'start_date': '2014-06-13',\n",
       "  'end_date': '2014-06-22',\n",
       "  'access': 29,\n",
       "  'discussion': 3,\n",
       "  'navigate': 11,\n",
       "  'page_close': 20,\n",
       "  'problem': 6,\n",
       "  'video': 12,\n",
       "  'wiki': 0,\n",
       "  'result': 1}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>page_close</th>\n",
       "      <th>problem</th>\n",
       "      <th>video</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-29</td>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>185</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>124</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date    end_date  access  discussion  navigate  page_close  problem  \\\n",
       "0  2014-05-29  2014-06-24     185          70        36         124       36   \n",
       "\n",
       "   video  wiki  \n",
       "0     50     1  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['start_date', 'end_date', 'access', 'discussion', 'navigate', 'page_close', 'problem', 'video', 'wiki']\n",
    "in_features = [['2014-05-29', '2014-06-24', 185, 70, 36, 124, 36, 50, 1]]\n",
    "#in_features = np.array(in_features).reshape(1,-1)\n",
    "pd.DataFrame(in_features, columns=cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://gowtham136:user136@cluster0.heyil.mongodb.net/<dbname>?retryWrites=true&w=majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.get_database('stdDropoutDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionD = db['MOOC_Visual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x1f552054780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = {'start_date': '2014-05-29',\n",
    "  'end_date': '2014-06-24',\n",
    "  'access': 185,\n",
    "  'discussion': 70,\n",
    "  'navigate': 36,\n",
    "  'page_close': 124,\n",
    "  'problem': 36,\n",
    "  'video': 50,\n",
    "  'wiki': 1,\n",
    "  'result': 0}\n",
    "collectionD.insert_one(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, {'_id': ObjectId('5ff21b9174b6e4ef98407410'), 'start_date': '2014-05-29', 'end_date': '2014-06-24', 'access': 185, 'discussion': 70, 'navigate': 36, 'page_close': 124, 'problem': 36, 'video': 50, 'wiki': 1, 'result': 0})\n"
     ]
    }
   ],
   "source": [
    "for record in enumerate(collectionD.find()):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "class database:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # self.client = MongoClient('localhost', 27017)\n",
    "            # self.db = self.client['stdDropoutDB']\n",
    "            # self.collectionD = self.db['MOOC_Visual']\n",
    "            self.client = MongoClient(\"mongodb+srv://gowtham136:user136@cluster0.heyil.mongodb.net/<dbname>?retryWrites=true&w=majority\")\n",
    "            self.db = self.client.get_database('stdDropoutDB')\n",
    "            self.collectionT = self.db['MOOC_Visual']\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "    # To add new row\n",
    "    def update_one(self, df):\n",
    "        record = df.to_dict(orient='records')[0]\n",
    "        self.collectionT.insert_one(record)     # Inserting Record\n",
    "        countOfrecords = self.collectionT.find().count()    # Finding number of records\n",
    "        message = f\"Record is successfully inserted at place {countOfrecords}\"  # Sending Message\n",
    "        self.client.close()\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-8986168a232a>:19: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  countOfrecords = self.collectionT.find().count()    # Finding number of records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record is successfully inserted at place 4\n"
     ]
    }
   ],
   "source": [
    "db = database()\n",
    "DbMessage = db.update_one(X)\n",
    "print(DbMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-6653ada5bce5>:19: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  countOfrecords = self.collectionT.find().count()    # Finding number of records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record is successfully inserted at place 3\n"
     ]
    }
   ],
   "source": [
    "DbMessage = db.update_one(X)\n",
    "print(DbMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_test1.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'D:\\\\DataScience\\\\02 INEURON\\\\ML_Projects\\\\Intership (iNeuron)\\\\Projects\\\\ml_education\\\\student_dropout\\\\Data\\\\Batch_Files\\\\'\n",
    "'D:\\\\DataScience\\\\02 INEURON\\\\ML_Projects\\\\Intership (iNeuron)\\\\Projects\\\\ml_education\\\\student_dropout\\\\Data\\\\Batch_Files\\\\X_test1.csv'.split(path)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
